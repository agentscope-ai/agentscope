{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Realtime Agent\n\nThe **realtime** agent is designed to handle real-time interactions, such as\nvoice conversations or live chat sessions.\nThe realtime agent in AgentScope features:\n\n- Integration with OpenAI, DashScope, Gemini, and other realtime model APIs\n- Unified event interface to simplify interactions with different realtime models\n- Support for tool calling capabilities\n- Support for multi-agent interactions\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The realtime agent is currently under active development. We welcome\n    community contributions, discussions, and feedback! If you're interested in\n    realtime agents, please join our discussion and development.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import asyncio\nimport os\nfrom agentscope.agent import RealtimeAgent\nfrom agentscope.realtime import (\n    DashScopeRealtimeModel,\n    OpenAIRealtimeModel,\n    GeminiRealtimeModel,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Realtime Models\n\nAgentScope currently supports the following realtime model APIs:\n\n.. list-table::\n   :header-rows: 1\n   :widths: 15 25 25 15 20\n\n   * - Provider\n     - Class\n     - Supported Models\n     - Input Modalities\n     - Tool Support\n   * - DashScope\n     - ``DashScopeRealtimeModel``\n     - ``qwen3-omni-flash-realtime``\n     - Text, Audio, Image\n     - No\n   * - OpenAI\n     - ``OpenAIRealtimeModel``\n     - ``gpt-4o-realtime-preview``\n     - Text, Audio\n     - Yes\n   * - Gemini\n     - ``GeminiRealtimeModel``\n     - ``gemini-2.5-flash-native-audio-preview-09-2025``\n     - Text, Audio, Image\n     - Yes\n\n\nHere are examples of initializing different realtime models:\n\n.. code-block:: python\n    :caption: Example of initializing different realtime models\n    # DashScope realtime model\n    dashscope_model = DashScopeRealtimeModel(\n        model_name=\"qwen3-omni-flash-realtime\",\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        voice=\"Cherry\",  # Options: \"Cherry\", \"Serena\", \"Ethan\", \"Chelsie\"\n        enable_input_audio_transcription=True,\n    )\n\n    # OpenAI realtime model\n    openai_model = OpenAIRealtimeModel(\n        model_name=\"gpt-4o-realtime-preview\",\n        api_key=os.getenv(\"OPENAI_API_KEY\"),\n        voice=\"alloy\",  # Options: \"alloy\", \"echo\", \"marin\", \"cedar\"\n        enable_input_audio_transcription=True,\n    )\n\n    # Gemini realtime model\n    gemini_model = GeminiRealtimeModel(\n        model_name=\"gemini-2.5-flash-native-audio-preview-09-2025\",\n        api_key=os.getenv(\"GEMINI_API_KEY\"),\n        voice=\"Puck\",  # Options: \"Puck\", \"Charon\", \"Kore\", \"Fenrir\"\n        enable_input_audio_transcription=True,\n    )\n\nThe realtime model provides the following key methods:\n\n.. list-table::\n   :header-rows: 1\n   :widths: 30 70\n\n   * - Method\n     - Description\n   * - ``connect(outgoing_queue, instructions, tools)``\n     - Establish WebSocket connection to the realtime model API\n   * - ``disconnect()``\n     - Close the WebSocket connection\n   * - ``send(data)``\n     - Send audio/text/image data to the realtime model for processing\n\nThe ``outgoing_queue`` parameter in ``connect()`` is an asyncio queue used to\nforward events from the realtime model to the outside (e.g., the agent or frontend).\n\n\n### Model Events Interface\n\nAgentScope provides a unified ``agentscope.realtime.ModelEvents`` interface to simplify\ninteractions with different realtime models. The following events are\nsupported:\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The \"session\" in ModelEvents refers to the WebSocket connection\n    session between the realtime model and the model API, not the session\n    between the frontend and backend.</p></div>\n\n.. list-table::\n   :header-rows: 1\n   :widths: 40 60\n\n   * - Event\n     - Description\n   * - ``ModelEvents.ModelSessionCreatedEvent``\n     - Session is successfully created\n   * - ``ModelEvents.ModelSessionEndedEvent``\n     - Session has ended\n   * - ``ModelEvents.ModelResponseCreatedEvent``\n     - Model begins generating a response\n   * - ``ModelEvents.ModelResponseDoneEvent``\n     - Model finished generating a response\n   * - ``ModelEvents.ModelResponseAudioDeltaEvent``\n     - Streaming audio data chunk from the model\n   * - ``ModelEvents.ModelResponseAudioDoneEvent``\n     - Audio response is complete\n   * - ``ModelEvents.ModelResponseAudioTranscriptDeltaEvent``\n     - Streaming transcription chunk of audio response\n   * - ``ModelEvents.ModelResponseAudioTranscriptDoneEvent``\n     - Audio transcription is complete\n   * - ``ModelEvents.ModelResponseToolUseDeltaEvent``\n     - Streaming tool call parameters\n   * - ``ModelEvents.ModelResponseToolUseDoneEvent``\n     - Tool call parameters are complete\n   * - ``ModelEvents.ModelInputTranscriptionDeltaEvent``\n     - Streaming transcription chunk of user input\n   * - ``ModelEvents.ModelInputTranscriptionDoneEvent``\n     - User input transcription is complete\n   * - ``ModelEvents.ModelInputStartedEvent``\n     - Detected start of user audio input (VAD)\n   * - ``ModelEvents.ModelInputDoneEvent``\n     - Detected end of user audio input (VAD)\n   * - ``ModelEvents.ModelErrorEvent``\n     - An error occurred\n\n\n\n## Creating a Realtime Agent\n\nThe ``RealtimeAgent`` serves as a bridge layer that:\n\n- Converts ``ModelEvents`` from realtime models into ``ServerEvents`` for\n  frontend and other agents\n- Receives ``ClientEvents`` from frontend or other agents and forwards them\n  to the realtime model API\n- Manages the agent's lifecycle and event queues\n\n### Server and Client Events\n\nAgentScope provides unified ``ServerEvents`` and ``ClientEvents`` for\ncommunication between backend and frontend:\n\n**ServerEvents** (Backend \u2192 Frontend):\n\n.. list-table::\n   :header-rows: 1\n   :widths: 40 60\n\n   * - Event\n     - Description\n   * - ``ServerEvents.ServerSessionCreatedEvent``\n     - Session created in backend\n   * - ``ServerEvents.ServerSessionUpdatedEvent``\n     - Session updated in backend\n   * - ``ServerEvents.ServerSessionEndedEvent``\n     - Session ended in backend\n   * - ``ServerEvents.AgentReadyEvent``\n     - Agent is ready to receive inputs\n   * - ``ServerEvents.AgentEndedEvent``\n     - Agent has ended\n   * - ``ServerEvents.AgentResponseCreatedEvent``\n     - Agent starts generating response\n   * - ``ServerEvents.AgentResponseDoneEvent``\n     - Agent finished generating response\n   * - ``ServerEvents.AgentResponseAudioDeltaEvent``\n     - Streaming audio chunk from agent\n   * - ``ServerEvents.AgentResponseAudioDoneEvent``\n     - Audio response complete\n   * - ``ServerEvents.AgentResponseAudioTranscriptDeltaEvent``\n     - Streaming transcription of agent response\n   * - ``ServerEvents.AgentResponseAudioTranscriptDoneEvent``\n     - Transcription complete\n   * - ``ServerEvents.AgentResponseToolUseDeltaEvent``\n     - Streaming tool call data\n   * - ``ServerEvents.AgentResponseToolUseDoneEvent``\n     - Tool call complete\n   * - ``ServerEvents.AgentResponseToolResultEvent``\n     - Tool execution result\n   * - ``ServerEvents.AgentInputTranscriptionDeltaEvent``\n     - Streaming transcription of user input\n   * - ``ServerEvents.AgentInputTranscriptionDoneEvent``\n     - Input transcription complete\n   * - ``ServerEvents.AgentInputStartedEvent``\n     - User audio input started\n   * - ``ServerEvents.AgentInputDoneEvent``\n     - User audio input ended\n   * - ``ServerEvents.AgentErrorEvent``\n     - An error occurred\n\n**ClientEvents** (Frontend \u2192 Backend):\n\n.. list-table::\n   :header-rows: 1\n   :widths: 40 60\n\n   * - Event\n     - Description\n   * - ``ClientEvents.ClientSessionCreateEvent``\n     - Create a new session with specified configuration\n   * - ``ClientEvents.ClientSessionEndEvent``\n     - End current session\n   * - ``ClientEvents.ClientResponseCreateEvent``\n     - Request agent to generate response immediately\n   * - ``ClientEvents.ClientResponseCancelEvent``\n     - Interrupt agent's current response\n   * - ``ClientEvents.ClientTextAppendEvent``\n     - Append text input\n   * - ``ClientEvents.ClientAudioAppendEvent``\n     - Append audio input\n   * - ``ClientEvents.ClientAudioCommitEvent``\n     - Commit audio input (signal end of input)\n   * - ``ClientEvents.ClientImageAppendEvent``\n     - Append image input\n   * - ``ClientEvents.ClientToolResultEvent``\n     - Send tool execution result\n\n### Initializing a Realtime Agent\n\nHere's how to create and use a realtime agent:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "async def example_realtime_agent() -> None:\n    \"\"\"Example of creating and using a realtime agent.\"\"\"\n    agent = RealtimeAgent(\n        name=\"Friday\",\n        sys_prompt=\"You are a helpful assistant named Friday.\",\n        model=DashScopeRealtimeModel(\n            model_name=\"qwen3-omni-flash-realtime\",\n            api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        ),\n    )\n\n    # Create a queue to receive messages from the agent\n    outgoing_queue = asyncio.Queue()\n\n    # The agent is now ready to handle inputs\n    # Handle outgoing messages in a separate task\n    async def handle_agent_messages():\n        while True:\n            event = await outgoing_queue.get()\n            # Process the event (e.g., send to frontend via WebSocket)\n            print(f\"Agent event: {event.type}\")\n\n    # Start the message handling task\n    asyncio.create_task(handle_agent_messages())\n\n    # Start the agent (establishes connection)\n    await agent.start(outgoing_queue)\n\n    # Stop the agent when done\n    await agent.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Starting Realtime Conversation\nNow we can set up a realtime conversation between a user and a realtime agent.\n\nHere we take FastAPI as an example backend framework to demonstrate how to set up\na realtime conversation.\n\n**Backend Setup (Server-side):**\n\nThe backend needs to:\n\n1. Create a WebSocket endpoint to accept frontend connections\n2. Create a ``RealtimeAgent`` when the session starts\n3. Forward ``ClientEvents`` from frontend to the agent\n4. Forward ``ServerEvents`` from agent to the frontend\n\n```python\nfrom fastapi import FastAPI, WebSocket\nfrom agentscope.agent import RealtimeAgent\nfrom agentscope.realtime import (\n    DashScopeRealtimeModel,\n    ClientEvents,\n    ServerEvents,\n)\n\napp = FastAPI()\n\n@app.websocket(\"/ws/{user_id}/{session_id}\")\nasync def websocket_endpoint(\n    websocket: WebSocket,\n    user_id: str,\n    session_id: str,\n):\n    await websocket.accept()\n\n    # Create queue for agent messages\n    frontend_queue = asyncio.Queue()\n\n    # Create agent\n    agent = RealtimeAgent(\n        name=\"Assistant\",\n        sys_prompt=\"You are a helpful assistant.\",\n        model=DashScopeRealtimeModel(\n            model_name=\"qwen3-omni-flash-realtime\",\n            api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        ),\n    )\n\n    # Start agent\n    await agent.start(frontend_queue)\n\n    # Forward messages from agent to frontend\n    async def send_to_frontend():\n        while True:\n            msg = await frontend_queue.get()\n            await websocket.send_json(msg.model_dump())\n\n    asyncio.create_task(send_to_frontend())\n\n    # Receive messages from frontend and forward to agent\n    while True:\n        data = await websocket.receive_json()\n        client_event = ClientEvents.from_json(data)\n        await agent.handle_input(client_event)\n```\n**Frontend Setup (Client-side):**\n\nThe frontend needs to:\n\n1. Establish WebSocket connection to the backend\n2. Send ``CLIENT_SESSION_CREATE`` event to initialize the session\n3. Capture audio from microphone and send via ``CLIENT_AUDIO_APPEND`` events\n4. Receive and handle ``ServerEvents`` (e.g., play audio, display transcripts)\n\n```javascript\n// Connect to WebSocket\nconst ws = new WebSocket('ws://localhost:8000/ws/user1/session1');\n\nws.onopen = () => {\n    // Create session\n    ws.send(JSON.stringify({\n        type: 'client_session_create',\n        config: {\n            instructions: 'You are a helpful assistant.',\n            user_name: 'User1'\n        }\n    }));\n};\n\n// Handle messages from backend\nws.onmessage = (event) => {\n    const data = JSON.parse(event.data);\n    if (data.type === 'response_audio_delta') {\n        // Play audio chunk\n        playAudio(data.delta);\n    }\n};\n\n// Send audio data\nfunction sendAudioChunk(audioData) {\n    ws.send(JSON.stringify({\n        type: 'client_audio_append',\n        session_id: 'session1',\n        audio: audioData,  // base64 encoded\n        format: { encoding: 'pcm16', sample_rate: 16000 }\n    }));\n}\n```\nFor a complete working example, see\n``examples/agent/realtime_voice_agent/`` in the AgentScope repository.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-Agent Realtime Conversation\n\nAgentScope supports multi-agent realtime interactions through the ``ChatRoom``\nclass.\n\nNote currently most realtime model APIs only support single-user interactions,\nbut AgentScope's architecture is designed to support multiple agents and users\nwhen API capabilities expand.\n\n### The Realtime ChatRoom\n\nAgentScope introduces the ``ChatRoom`` class to manage multiple realtime\nagents in a shared conversation space. The ChatRoom provides:\n\n- Centralized management of multiple ``RealtimeAgent`` instances\n- Automatic message broadcasting between agents\n- Unified message queue for frontend communication\n- Lifecycle management for all agents in the room\n\n### Using ChatRoom\n\nThe usage of ``ChatRoom`` is similar to ``RealtimeAgent``:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "async def example_chat_room() -> None:\n    \"\"\"Example of using ChatRoom with multiple realtime agents.\"\"\"\n    from agentscope.pipeline import ChatRoom\n    from agentscope.agent import RealtimeAgent\n    from agentscope.realtime import DashScopeRealtimeModel\n\n    # Create multiple agents\n    agent1 = RealtimeAgent(\n        name=\"Agent1\",\n        sys_prompt=\"You are Agent1, a helpful assistant.\",\n        model=DashScopeRealtimeModel(\n            model_name=\"qwen3-omni-flash-realtime\",\n            api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        ),\n    )\n\n    agent2 = RealtimeAgent(\n        name=\"Agent2\",\n        sys_prompt=\"You are Agent2, a helpful assistant.\",\n        model=DashScopeRealtimeModel(\n            model_name=\"qwen3-omni-flash-realtime\",\n            api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        ),\n    )\n\n    # Create a chat room with multiple agents\n    chat_room = ChatRoom(agents=[agent1, agent2])\n\n    # Create queue to receive messages from all agents\n    outgoing_queue = asyncio.Queue()\n\n    # Start the chat room\n    await chat_room.start(outgoing_queue)\n\n    # Handle input from frontend\n    # The chat room will broadcast to all agents\n    from agentscope.realtime import ClientEvents\n\n    client_event = ClientEvents.ClientTextAppendEvent(\n        session_id=\"session1\",\n        text=\"Hello everyone!\",\n    )\n    await chat_room.handle_input(client_event)\n\n    # Stop the chat room when done\n    await chat_room.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Roadmap\n\nThe realtime agent feature is currently experimental and under active\ndevelopment. The future plans include:\n\n- Support for more realtime model APIs\n- Enhanced memory management for conversation history\n- Comprehensive tool calling support across all providers\n- Multi-user voice interaction support\n- Improved VAD (Voice Activity Detection) configuration\n- Better error handling and recovery mechanisms\n\nWe welcome contributions and feedback from the community to help shape the\nfuture of realtime agents in AgentScope!\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}