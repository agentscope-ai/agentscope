
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorial/task_model.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_tutorial_task_model.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorial_task_model.py:


.. _model:

æ¨¡å‹
====================

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä»‹ç» AgentScope ä¸­é›†æˆçš„æ¨¡å‹ APIã€å¦‚ä½•ä½¿ç”¨å®ƒä»¬ï¼Œä»¥åŠå¦‚ä½•é›†æˆæ–°çš„æ¨¡å‹ APIã€‚
AgentScope ç›®å‰æ”¯æŒçš„æ¨¡å‹ API å’Œæ¨¡å‹æä¾›å•†åŒ…æ‹¬ï¼š

.. list-table::
    :header-rows: 1

    * - API
      - ç±»
      - å…¼å®¹
      - æµå¼
      - å·¥å…·
      - è§†è§‰
      - æ¨ç†
    * - OpenAI
      - ``OpenAIChatModel``
      - vLLM, DeepSeek
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - DashScope
      - ``DashScopeChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - Anthropic
      - ``AnthropicChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - Gemini
      - ``GeminiChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…
    * - Ollama
      - ``OllamaChatModel``
      -
      - âœ…
      - âœ…
      - âœ…
      - âœ…

.. note:: å½“ä½¿ç”¨ vLLM æ—¶ï¼Œéœ€è¦åœ¨éƒ¨ç½²æ—¶ä¸ºä¸åŒæ¨¡å‹é…ç½®ç›¸åº”çš„å·¥å…·è°ƒç”¨å‚æ•°ï¼Œä¾‹å¦‚ ``--enable-auto-tool-choice``ã€``--tool-call-parser`` ç­‰å‚æ•°ã€‚æ›´å¤šè¯¦æƒ…è¯·å‚è€ƒ `vLLM å®˜æ–¹æ–‡æ¡£ <https://docs.vllm.ai/en/latest/features/tool_calling.html>`_ã€‚

.. note:: å…¼å®¹ OpenAI API çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ vLLM éƒ¨ç½²çš„æ¨¡å‹ï¼‰ï¼Œæ¨èä½¿ç”¨ ``OpenAIChatModel``ï¼Œå¹¶é€šè¿‡ ``client_kwargs={"base_url": "http://your-api-endpoint"}`` å‚æ•°æŒ‡å®š API ç«¯ç‚¹ã€‚ä¾‹å¦‚ï¼š

    .. code-block:: python

        OpenAIChatModel(client_kwargs={"base_url": "http://localhost:8000/v1"})

.. note:: æ¨¡å‹çš„è¡Œä¸ºå‚æ•°ï¼ˆå¦‚æ¸©åº¦ã€æœ€å¤§é•¿åº¦ç­‰ï¼‰å¯ä»¥é€šè¿‡ ``generate_kwargs`` å‚æ•°åœ¨æ„é€ å‡½æ•°ä¸­æå‰è®¾å®šã€‚ä¾‹å¦‚ï¼š

    .. code-block:: python

        OpenAIChatModel(generate_kwargs={"temperature": 0.3, "max_tokens": 1000})

ä¸ºäº†æä¾›ç»Ÿä¸€çš„æ¨¡å‹æ¥å£ï¼Œä¸Šè¿°æ‰€æœ‰ç±»å‡è¢«ç»Ÿä¸€ä¸ºï¼š

- ``__call__`` å‡½æ•°çš„å‰ä¸‰ä¸ªå‚æ•°æ˜¯ ``messages``ï¼Œ``tools`` å’Œ ``tool_choice``ï¼Œåˆ†åˆ«æ˜¯è¾“å…¥æ¶ˆæ¯ï¼Œå·¥å…·å‡½æ•°çš„ JSON schemaï¼Œä»¥åŠå·¥å…·é€‰æ‹©çš„æ¨¡å¼ã€‚
- éæµå¼è¿”å›æ—¶ï¼Œè¿”å›ç±»å‹æ˜¯ ``ChatResponse`` å®ä¾‹ï¼›æµå¼è¿”å›æ—¶ï¼Œè¿”å›çš„æ˜¯ ``ChatResponse`` çš„å¼‚æ­¥ç”Ÿæˆå™¨ã€‚

.. note:: ä¸åŒçš„æ¨¡å‹ API åœ¨è¾“å…¥æ¶ˆæ¯æ ¼å¼ä¸Šæœ‰æ‰€ä¸åŒï¼ŒAgentScope é€šè¿‡ formatter æ¨¡å—å¤„ç†æ¶ˆæ¯çš„è½¬æ¢ï¼Œè¯·å‚è€ƒ :ref:`format`ã€‚

``ChatResponse`` åŒ…å«å¤§æ¨¡å‹ç”Ÿæˆçš„æ¨ç†/æ–‡æœ¬/å·¥å…·ä½¿ç”¨å†…å®¹ã€èº«ä»½ã€åˆ›å»ºæ—¶é—´å’Œä½¿ç”¨ä¿¡æ¯ã€‚

.. GENERATED FROM PYTHON SOURCE LINES 80-105

.. code-block:: Python

    import asyncio
    import json
    import os

    from agentscope.message import TextBlock, ToolUseBlock, ThinkingBlock, Msg
    from agentscope.model import ChatResponse, DashScopeChatModel

    response = ChatResponse(
        content=[
            ThinkingBlock(
                type="thinking",
                thinking="æˆ‘åº”è¯¥åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚",
            ),
            TextBlock(type="text", text="æˆ‘å°†åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚"),
            ToolUseBlock(
                type="tool_use",
                id="642n298gjna",
                name="google_search",
                input={"query": "AgentScope"},
            ),
        ],
    )

    print(response)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ChatResponse(content=[{'type': 'thinking', 'thinking': 'æˆ‘åº”è¯¥åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚'}, {'type': 'text', 'text': 'æˆ‘å°†åœ¨ Google ä¸Šæœç´¢ AgentScopeã€‚'}, {'type': 'tool_use', 'id': '642n298gjna', 'name': 'google_search', 'input': {'query': 'AgentScope'}}], id='2026-02-12 08:38:33.046_231c27', created_at='2026-02-12 08:38:33.046', type='chat', usage=None, metadata=None)




.. GENERATED FROM PYTHON SOURCE LINES 106-107

ä»¥ ``DashScopeChatModel`` ä¸ºä¾‹ï¼Œè°ƒç”¨å’Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š

.. GENERATED FROM PYTHON SOURCE LINES 107-132

.. code-block:: Python



    async def example_model_call() -> None:
        """ä½¿ç”¨ DashScopeChatModel çš„ç¤ºä¾‹ã€‚"""
        model = DashScopeChatModel(
            model_name="qwen-max",
            api_key=os.environ["DASHSCOPE_API_KEY"],
            stream=False,
        )

        res = await model(
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼"},
            ],
        )

        # æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨å“åº”å†…å®¹åˆ›å»º ``Msg`` å¯¹è±¡
        msg_res = Msg("Friday", res.content, "assistant")

        print("LLM è¿”å›ç»“æœ:", res)
        print("ä½œä¸º Msg çš„å“åº”:", msg_res)


    asyncio.run(example_model_call())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    LLM è¿”å›ç»“æœ: ChatResponse(content=[{'type': 'text', 'text': 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘èƒ½å¸®åŠ©ä½ çš„å—ï¼Ÿ'}], id='2026-02-12 08:38:35.301_d4c9c3', created_at='2026-02-12 08:38:35.301', type='chat', usage=ChatUsage(input_tokens=10, output_tokens=8, time=2.254512, type='chat', metadata=GenerationUsage(input_tokens=10, output_tokens=8)), metadata=None)
    ä½œä¸º Msg çš„å“åº”: Msg(id='HjLD2M3bNy8nX9HuuwN9un', name='Friday', content=[{'type': 'text', 'text': 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘èƒ½å¸®åŠ©ä½ çš„å—ï¼Ÿ'}], role='assistant', metadata={}, timestamp='2026-02-12 08:38:35.301', invocation_id='None')




.. GENERATED FROM PYTHON SOURCE LINES 133-140

æµå¼è¿”å›
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
è¦å¯ç”¨æµå¼è¿”å›ï¼Œè¯·åœ¨æ¨¡å‹çš„æ„é€ å‡½æ•°ä¸­å°† ``stream`` å‚æ•°è®¾ç½®ä¸º ``True``ã€‚
æµå¼è¿”å›ä¸­ï¼Œ``__call__`` æ–¹æ³•å°†è¿”å›ä¸€ä¸ª **å¼‚æ­¥ç”Ÿæˆå™¨**ï¼Œè¯¥ç”Ÿæˆå™¨è¿­ä»£è¿”å› ``ChatResponse`` å®ä¾‹ã€‚

.. note:: AgentScope ä¸­çš„æµå¼è¿”å›ç»“æœä¸º **ç´¯åŠ å¼**ï¼Œè¿™æ„å‘³ç€æ¯ä¸ª chunk ä¸­çš„å†…å®¹åŒ…å«æ‰€æœ‰ä¹‹å‰çš„å†…å®¹åŠ ä¸Šæ–°ç”Ÿæˆçš„å†…å®¹ã€‚


.. GENERATED FROM PYTHON SOURCE LINES 140-170

.. code-block:: Python



    async def example_streaming() -> None:
        """ä½¿ç”¨æµå¼æ¨¡å‹çš„ç¤ºä¾‹ã€‚"""
        model = DashScopeChatModel(
            model_name="qwen-max",
            api_key=os.environ["DASHSCOPE_API_KEY"],
            stream=True,
        )

        generator = await model(
            messages=[
                {
                    "role": "user",
                    "content": "ä» 1 æ•°åˆ° 20ï¼ŒåªæŠ¥å‘Šæ•°å­—ï¼Œä¸è¦ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚",
                },
            ],
        )
        print("å“åº”çš„ç±»å‹:", type(generator))

        i = 0
        async for chunk in generator:
            print(f"å— {i}")
            print(f"\tç±»å‹: {type(chunk.content)}")
            print(f"\t{chunk}\n")
            i += 1


    asyncio.run(example_streaming())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    å“åº”çš„ç±»å‹: <class 'async_generator'>
    å— 0
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1'}], id='2026-02-12 08:38:36.562_5ddc92', created_at='2026-02-12 08:38:36.562', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=1, time=1.259054, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=1)), metadata=None)

    å— 1
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n'}], id='2026-02-12 08:38:36.654_fee9b0', created_at='2026-02-12 08:38:36.654', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=2, time=1.351159, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=2)), metadata=None)

    å— 2
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3'}], id='2026-02-12 08:38:36.847_8c4cb1', created_at='2026-02-12 08:38:36.847', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=5, time=1.544505, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=5)), metadata=None)

    å— 3
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n'}], id='2026-02-12 08:38:36.942_d0237d', created_at='2026-02-12 08:38:36.942', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=8, time=1.639172, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=8)), metadata=None)

    å— 4
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n'}], id='2026-02-12 08:38:38.165_703469', created_at='2026-02-12 08:38:38.165', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=14, time=2.862119, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=14)), metadata=None)

    å— 5
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10'}], id='2026-02-12 08:38:38.540_6c87c4', created_at='2026-02-12 08:38:38.540', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=20, time=3.237683, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=20)), metadata=None)

    å— 6
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12'}], id='2026-02-12 08:38:38.724_e736d4', created_at='2026-02-12 08:38:38.725', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=26, time=3.421764, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=26)), metadata=None)

    å— 7
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14'}], id='2026-02-12 08:38:38.905_0e1163', created_at='2026-02-12 08:38:38.905', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=32, time=3.602196, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=32)), metadata=None)

    å— 8
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16'}], id='2026-02-12 08:38:39.112_7ad6ab', created_at='2026-02-12 08:38:39.112', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=38, time=3.809294, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=38)), metadata=None)

    å— 9
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18'}], id='2026-02-12 08:38:39.290_e15376', created_at='2026-02-12 08:38:39.290', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=44, time=3.987209, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=44)), metadata=None)

    å— 10
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20'}], id='2026-02-12 08:38:39.474_30d506', created_at='2026-02-12 08:38:39.474', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=50, time=4.171038, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=50)), metadata=None)

    å— 11
            ç±»å‹: <class 'list'>
            ChatResponse(content=[{'type': 'text', 'text': '1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20'}], id='2026-02-12 08:38:40.487_e39a75', created_at='2026-02-12 08:38:40.487', type='chat', usage=ChatUsage(input_tokens=26, output_tokens=50, time=5.184613, type='chat', metadata=GenerationUsage(input_tokens=26, output_tokens=50)), metadata=None)





.. GENERATED FROM PYTHON SOURCE LINES 171-175

æ¨ç†æ¨¡å‹
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
AgentScope é€šè¿‡æä¾› ``ThinkingBlock`` æ¥æ”¯æŒæ¨ç†æ¨¡å‹ã€‚


.. GENERATED FROM PYTHON SOURCE LINES 175-200

.. code-block:: Python



    async def example_reasoning() -> None:
        """ä½¿ç”¨æ¨ç†æ¨¡å‹çš„ç¤ºä¾‹ã€‚"""
        model = DashScopeChatModel(
            model_name="qwen-turbo",
            api_key=os.environ["DASHSCOPE_API_KEY"],
            enable_thinking=True,
        )

        res = await model(
            messages=[
                {"role": "user", "content": "æˆ‘æ˜¯è°ï¼Ÿ"},
            ],
        )

        last_chunk = None
        async for chunk in res:
            last_chunk = chunk
        print("æœ€ç»ˆå“åº”:")
        print(last_chunk)


    asyncio.run(example_reasoning())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    æœ€ç»ˆå“åº”:
    ChatResponse(content=[{'type': 'thinking', 'thinking': 'å¥½çš„ï¼Œç”¨æˆ·é—®â€œæˆ‘æ˜¯è°ï¼Ÿâ€ï¼Œè¿™æ˜¯ä¸€ä¸ªå“²å­¦æ€§å¾ˆå¼ºçš„é—®é¢˜ï¼Œéœ€è¦æ·±å…¥æ€è€ƒã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦è€ƒè™‘ç”¨æˆ·çš„èƒŒæ™¯å’Œæ„å›¾ã€‚å¯èƒ½ç”¨æˆ·æ­£åœ¨ç»å†è‡ªæˆ‘åæ€ï¼Œæˆ–è€…å¯¹å­˜åœ¨æœ¬è´¨æ„Ÿåˆ°å›°æƒ‘ã€‚ä¹Ÿæœ‰å¯èƒ½æ˜¯åœ¨å¯»æ‰¾æŸç§å¿ƒç†ä¸Šçš„ç­”æ¡ˆï¼Œæˆ–è€…åªæ˜¯å‡ºäºå¥½å¥‡ã€‚\n\næ¥ä¸‹æ¥ï¼Œæˆ‘åº”è¯¥åˆ†æè¿™ä¸ªé—®é¢˜çš„ä¸åŒå±‚é¢ã€‚ä»å“²å­¦è§’åº¦çœ‹ï¼Œè¿™å¯èƒ½æ¶‰åŠæœ¬ä½“è®ºã€è®¤è¯†è®ºï¼Œæˆ–è€…å­˜åœ¨ä¸»ä¹‰ã€‚æ¯”å¦‚ï¼Œç¬›å¡å°”çš„â€œæˆ‘æ€æ•…æˆ‘åœ¨â€ï¼Œæˆ–è€…ä½›æ•™ä¸­çš„â€œæ— æˆ‘â€æ¦‚å¿µã€‚åŒæ—¶ï¼Œå¿ƒç†å­¦è§’åº¦å¯èƒ½æ¶‰åŠè‡ªæˆ‘è®¤åŒã€äººæ ¼å‘å±•ç­‰ã€‚\n\nè¿˜è¦è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„æ·±å±‚éœ€æ±‚ã€‚ä»–ä»¬å¯èƒ½åœ¨å¯»æ‰¾è‡ªæˆ‘è®¤çŸ¥çš„æ–¹æ³•ï¼Œæˆ–è€…åœ¨é¢å¯¹äººç”Ÿå›°æƒ‘æ—¶å¯»æ±‚æŒ‡å¯¼ã€‚ä¹Ÿæœ‰å¯èƒ½æ˜¯åœ¨è¿›è¡ŒæŸç§å“²å­¦æ¢ç´¢ï¼Œæˆ–è€…éœ€è¦æƒ…æ„Ÿæ”¯æŒã€‚\n\néœ€è¦ç¡®ä¿å›ç­”æ—¢å…¨é¢åˆæœ‰æ·±åº¦ï¼ŒåŒæ—¶é¿å…è¿‡äºå­¦æœ¯åŒ–ï¼Œä¿æŒæ˜“æ‡‚ã€‚å¯èƒ½éœ€è¦åˆ†ç‚¹é˜è¿°ä¸åŒè§’åº¦çš„è§‚ç‚¹ï¼Œæ¯”å¦‚å“²å­¦ã€å¿ƒç†å­¦ã€å®—æ•™ç­‰ï¼Œå¹¶ç»™å‡ºä¸€äº›å®é™…çš„ä¾‹å­æˆ–æ–¹æ³•ï¼Œå¸®åŠ©ç”¨æˆ·è¿›è¡Œè‡ªæˆ‘æ¢ç´¢ã€‚\n\nè¿˜è¦æ³¨æ„é¿å…æ­¦æ–­ä¸‹ç»“è®ºï¼Œå› ä¸ºâ€œæˆ‘æ˜¯è°â€æ²¡æœ‰æ ‡å‡†ç­”æ¡ˆï¼Œæ¯ä¸ªäººéƒ½æœ‰ä¸åŒçš„ç†è§£å’Œä½“éªŒã€‚åº”è¯¥é¼“åŠ±ç”¨æˆ·è¿›è¡Œè‡ªæˆ‘åæ€ï¼Œæˆ–è€…æ¨èä¸€äº›å·¥å…·å’Œæ–¹æ³•ï¼Œå¦‚å†™æ—¥è®°ã€å†¥æƒ³ã€å¿ƒç†å’¨è¯¢ç­‰ã€‚\n\næœ€åï¼Œä¿æŒè¯­æ°”å‹å¥½å’Œå¼€æ”¾ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°è¢«ç†è§£å’Œæ”¯æŒï¼ŒåŒæ—¶æä¾›è¶³å¤Ÿçš„ä¿¡æ¯è®©ä»–ä»¬èƒ½å¤Ÿè¿›ä¸€æ­¥æ€è€ƒå’Œæ¢ç´¢ã€‚\n'}, {'type': 'text', 'text': 'â€œæˆ‘æ˜¯è°ï¼Ÿâ€æ˜¯ä¸€ä¸ªæ·±åˆ»è€Œå¤æ‚çš„é—®é¢˜ï¼Œä¸åŒçš„äººã€ä¸åŒçš„æ–‡åŒ–ã€ä¸åŒçš„å“²å­¦ä½“ç³»å¯èƒ½ä¼šç»™å‡ºä¸åŒçš„ç­”æ¡ˆã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¯èƒ½çš„è§†è§’ï¼Œæˆ–è®¸èƒ½å¸®åŠ©ä½ æ›´æ·±å…¥åœ°æ€è€ƒè¿™ä¸ªé—®é¢˜ï¼š\n\n---\n\n### **1. å“²å­¦è§†è§’**\n- **ç¬›å¡å°”çš„â€œæˆ‘æ€æ•…æˆ‘åœ¨â€**ï¼šæ³•å›½å“²å­¦å®¶ç¬›å¡å°”è®¤ä¸ºï¼Œâ€œæˆ‘æ€â€æ˜¯ç¡®å®šå­˜åœ¨çš„å”¯ä¸€è¯æ®ï¼Œå› æ­¤â€œæˆ‘â€æ˜¯æ€è€ƒçš„ä¸»ä½“ã€‚ä½†è¿™é‡Œçš„â€œæˆ‘â€å¯èƒ½åªæ˜¯ä¸€ä¸ªæ€ç»´çš„è½½ä½“ï¼Œè€Œéæœ¬è´¨ã€‚\n- **ä½›æ•™çš„â€œæ— æˆ‘â€**ï¼šä½›æ•™è®¤ä¸ºâ€œæˆ‘â€æ˜¯äº”è•´ï¼ˆè‰²ã€å—ã€æƒ³ã€è¡Œã€è¯†ï¼‰çš„æš‚æ—¶ç»„åˆï¼Œå¹¶ä¸å­˜åœ¨æ°¸æ’ä¸å˜çš„â€œè‡ªæˆ‘â€ã€‚è¿™ç§è§‚ç‚¹æŒ‘æˆ˜äº†å¯¹â€œæˆ‘â€çš„æ‰§ç€ã€‚\n- **å­˜åœ¨ä¸»ä¹‰**ï¼šè¨ç‰¹ç­‰å­˜åœ¨ä¸»ä¹‰è€…è®¤ä¸ºï¼Œâ€œæˆ‘â€æ˜¯é€šè¿‡è‡ªç”±é€‰æ‹©å’Œè¡ŒåŠ¨ä¸æ–­å¡‘é€ çš„ã€‚äººä¸æ˜¯å…ˆéªŒçš„å­˜åœ¨ï¼Œè€Œæ˜¯é€šè¿‡è¡ŒåŠ¨å®šä¹‰è‡ªå·±ã€‚\n\n---\n\n### **2. å¿ƒç†å­¦è§†è§’**\n- **è‡ªæˆ‘è®¤åŒ**ï¼šå¿ƒç†å­¦å®¶åŸƒé‡Œå…‹æ£®æå‡ºï¼Œäººçš„å‘å±•è¿‡ç¨‹ä¸­ä¼šä¸æ–­æ¢ç´¢â€œæˆ‘æ˜¯è°â€çš„é—®é¢˜ï¼Œå½¢æˆç¨³å®šçš„è‡ªæˆ‘è®¤åŒã€‚è¿™åŒ…æ‹¬èŒä¸šã€ä»·å€¼è§‚ã€äººé™…å…³ç³»ç­‰å¤šæ–¹é¢ã€‚\n- **äººæ ¼çš„å¤šé¢æ€§**ï¼šå¿ƒç†å­¦è®¤ä¸ºâ€œæˆ‘â€æ˜¯å¤šç§è§’è‰²çš„é›†åˆï¼ˆå¦‚å­¦ç”Ÿã€æœ‹å‹ã€å­å¥³ï¼‰ï¼Œè€Œéå•ä¸€çš„å›ºå®šèº«ä»½ã€‚ä¸åŒæƒ…å¢ƒä¸‹ï¼Œâ€œæˆ‘â€å¯èƒ½è¡¨ç°å‡ºä¸åŒçš„ç‰¹è´¨ã€‚\n- **æ½œæ„è¯†ä¸è®°å¿†**ï¼šå¼—æ´›ä¼Šå¾·è®¤ä¸ºâ€œæˆ‘â€ç”±æœ¬æˆ‘ã€è‡ªæˆ‘å’Œè¶…æˆ‘æ„æˆï¼Œè€Œè®°å¿†å’Œç»éªŒåˆ™å¡‘é€ äº†æˆ‘ä»¬çš„è‡ªæˆ‘è®¤çŸ¥ã€‚\n\n---\n\n### **3. å®—æ•™ä¸çµæ€§è§†è§’**\n- **åŸºç£æ•™**ï¼šè®¤ä¸ºâ€œæˆ‘â€æ˜¯ä¸Šå¸åˆ›é€ çš„ç‹¬ç‰¹ä¸ªä½“ï¼Œä½†æœ€ç»ˆçš„å½’å±æ˜¯ä¸ç¥åˆä¸€ã€‚\n- **é“æ•™**ï¼šå¼ºè°ƒâ€œé“æ³•è‡ªç„¶â€ï¼Œâ€œæˆ‘â€æ˜¯å¤©åœ°ä¸‡ç‰©çš„ä¸€éƒ¨åˆ†ï¼Œéœ€å›å½’æœ¬çœŸã€‚\n- **ç¥ç§˜ä¸»ä¹‰**ï¼šè®¸å¤šçµæ€§ä¼ ç»Ÿï¼ˆå¦‚è‹è²æ´¾ã€ä½›æ•™ç¦…å®—ï¼‰è®¤ä¸ºâ€œæˆ‘â€æ˜¯å¹»è±¡ï¼ŒçœŸæ­£çš„è‡ªæˆ‘æ˜¯è¶…è¶Šä¸ªä½“çš„â€œä¸€ä½“æ€§â€æˆ–â€œç©ºæ€§â€ã€‚\n\n---\n\n### **4. ç§‘å­¦è§†è§’**\n- **ç”Ÿç‰©å­¦**ï¼šä»åŸºå› ã€ç¥ç»ç§‘å­¦è§’åº¦çœ‹ï¼Œâ€œæˆ‘â€æ˜¯å¤§è„‘ç¥ç»å…ƒæ´»åŠ¨çš„äº§ç‰©ï¼Œæ˜¯ç‰©è´¨ä¸–ç•Œçš„å¤æ‚ç³»ç»Ÿã€‚\n- **è¿›åŒ–è®º**ï¼šäººç±»çš„â€œè‡ªæˆ‘æ„è¯†â€æ˜¯è¿›åŒ–çš„ç»“æœï¼Œç”¨äºé€‚åº”ç¯å¢ƒå’Œç”Ÿå­˜ã€‚\n\n---\n\n### **5. æ—¥å¸¸ç”Ÿæ´»çš„ç­”æ¡ˆ**\n- **èº«ä»½æ ‡ç­¾**ï¼šä½ å¯èƒ½æ˜¯â€œæŸäººâ€çš„å­©å­ã€æœ‹å‹ã€åŒäº‹ã€çˆ±å¥½è€…çš„èº«ä»½ã€‚\n- **å†…åœ¨ç‰¹è´¨**ï¼šä½ å¯èƒ½è®¤ä¸ºè‡ªå·±æ˜¯å–„è‰¯çš„ã€å¥½å¥‡çš„ã€åšéŸ§çš„ï¼Œæˆ–æœ‰æŸç§ç‹¬ç‰¹æ€§æ ¼ã€‚\n- **åŠ¨æ€å˜åŒ–**ï¼šéšç€æ—¶é—´ã€ç»å†å’Œæˆé•¿ï¼Œâ€œæˆ‘â€å¯èƒ½ä¸æ–­æ¼”å˜ï¼Œæ²¡æœ‰å›ºå®šç­”æ¡ˆã€‚\n\n---\n\n### **6. ä½ å¯èƒ½éœ€è¦çš„ç­”æ¡ˆ**\n- **å¦‚æœè¿™æ˜¯å“²å­¦æ€è€ƒ**ï¼šå¯ä»¥å°è¯•è¿½é—®â€œæˆ‘â€æ˜¯å¦æ˜¯æ°¸æ’çš„ï¼Ÿâ€œæˆ‘â€çš„è¾¹ç•Œåœ¨å“ªé‡Œï¼Ÿ  \n- **å¦‚æœè¿™æ˜¯æƒ…æ„Ÿå›°æƒ‘**ï¼šä¹Ÿè®¸ä½ æ­£åœ¨å¯»æ‰¾å½’å±æ„Ÿæˆ–æ„ä¹‰ï¼Œå¯ä»¥å°è¯•è®°å½•æƒ…ç»ªã€åæ€ä»·å€¼è§‚ã€‚  \n- **å¦‚æœè¿™æ˜¯æ¢ç´¢è‡ªæˆ‘**ï¼šå¯ä»¥é€šè¿‡å†¥æƒ³ã€å†™ä½œã€ä¸ä»–äººå¯¹è¯ç­‰æ–¹å¼ï¼Œé€æ¸æ¥è¿‘ç­”æ¡ˆã€‚\n\n---\n\n### **æœ€å**\nâ€œæˆ‘æ˜¯è°ï¼Ÿâ€æ²¡æœ‰æ ‡å‡†ç­”æ¡ˆï¼Œå®ƒæ›´åƒæ˜¯ä¸€é¢é•œå­ï¼Œæ˜ ç…§å‡ºä½ å¯¹ç”Ÿå‘½çš„ç†è§£ä¸æ¸´æœ›ã€‚æˆ–è®¸ç­”æ¡ˆä¸åœ¨è¿œæ–¹ï¼Œè€Œåœ¨ä½ æ­¤åˆ»çš„æ€è€ƒä¸æ„Ÿå—ä¸­ã€‚  \nå¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥åˆ†äº«æ›´å¤šä½ çš„æƒ³æ³•ï¼Œæˆ‘ä»¬å¯ä»¥ä¸€èµ·æ¢ç´¢ã€‚ ğŸŒ±'}], id='2026-02-12 08:38:54.436_0e1a1d', created_at='2026-02-12 08:38:54.436', type='chat', usage=ChatUsage(input_tokens=11, output_tokens=996, time=13.943785, type='chat', metadata=GenerationUsage(input_tokens=11, output_tokens=996)), metadata=None)




.. GENERATED FROM PYTHON SOURCE LINES 201-209

å·¥å…· API
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ä¸åŒçš„æ¨¡å‹æä¾›å•†åœ¨å·¥å…· API æ–¹é¢æœ‰æ‰€ä¸åŒï¼Œä¾‹å¦‚å·¥å…· JSON schemaã€å·¥å…·è°ƒç”¨/å“åº”æ ¼å¼ã€‚
ä¸ºäº†æä¾›ç»Ÿä¸€çš„æ¥å£ï¼ŒAgentScope é€šè¿‡ä»¥ä¸‹æ–¹å¼è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼š

- æä¾›äº†ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨ç»“æ„ block :ref:`ToolUseBlock <tool-block>` å’Œå·¥å…·å“åº”ç»“æ„ :ref:`ToolResultBlock <tool-block>`ã€‚
- åœ¨æ¨¡å‹ç±»çš„ ``__call__`` æ–¹æ³•ä¸­æä¾›ç»Ÿä¸€çš„å·¥å…·æ¥å£ ``tools``ï¼Œæ¥å—å·¥å…· JSON schema åˆ—è¡¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š


.. GENERATED FROM PYTHON SOURCE LINES 209-230

.. code-block:: Python


    json_schemas = [
        {
            "type": "function",
            "function": {
                "name": "google_search",
                "description": "åœ¨ Google ä¸Šæœç´¢æŸ¥è¯¢ã€‚",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "æœç´¢æŸ¥è¯¢ã€‚",
                        },
                    },
                    "required": ["query"],
                },
            },
        },
    ]








.. GENERATED FROM PYTHON SOURCE LINES 231-236

è¿›ä¸€æ­¥é˜…è¯»
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
- :ref:`message`
- :ref:`prompt`



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 21.396 seconds)


.. _sphx_glr_download_tutorial_task_model.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: task_model.ipynb <task_model.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: task_model.py <task_model.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: task_model.zip <task_model.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
